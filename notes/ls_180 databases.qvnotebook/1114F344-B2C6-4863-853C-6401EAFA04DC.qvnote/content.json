{
  "title": "Gerneral notes",
  "cells": [
    {
      "type": "markdown",
      "data": "|Term|Defintion|\n|--|--|\n|Relational Databas |  A structured collection of data that follows a **relational model**|\n|RDBMS| Relational Database Management Syste.  A software application for managing relational databses, such as PostgreSQL.|\n|Relation| A set of individual but related data entries; analogous to a database table.|\n|SQL|Structured Query Language.  The language used by RDBMSs.|\n|SQL Statement| A SQL command used to access/use the database or the data within the database via the SQL language|\n|SQL query|  A subset of a \"SQL Statement\".  A query is a way to serach, or lookup data within a database, as opposed ot updating or chaning data.|\n\n### SQK Sub-languages\n\nSQL can be thought of as comprising three separate sub-languages, each converend with a specific aspect of manipulatin gor interaciting with a database.  The three sublangauges are:\n\n- *DDL: Data Definition Language:*  Used to define the structure of a database and the tables and columns within it.\n- *DML:Data Manipulation Language.* Used to retrieve or modify data stored in a database. `SELECT` queries are part of DML.\n- *DCL: Data Control Langauge*.  Used to determine what various users are allowed to do when interacting with a database.\n\n\n### Data vs Schema\n\nFor example, when we tell PostgreSQL to `SELECT customer_name FROM orders WHERE side = \"Fries\";` hwo does it know what `customer_name` is, or what `orders` is?  Having interpreted thse instructions, how does PostgreSQL know what data to send back in response?\n\nPart of the answer here is in the syntax that we used to issue the statement, adn we'll look a lot more closely at this syntax later in this book.  Another important concept to understahdn here is the roels that schema and data play in a database, and how the relationship between the two is what gives the database its power. \n\nSchema is concerned wiht the **structure** of a database.  This structure is defined by things usch as the names of tables and table columsn, the data types of those coumns and any contstraints that they may have.\n\nData is concerned with the **contents** of a database.  These are the actual values associated with specific rows and columns in a database table.\n\nSchema and data work together in order to let us interact with a database in useful ways.  Schema without data would just be a bunch of empty tables.  Data wihtout schema we would eb back to the idea of unstructured data we discuess in the opening chapter of this book. \n\n### psql session commands\n\n| *PSQL Command* | *Notes*|\n|--|--|\n|`\\l` or `\\list`| displays all databases|\n|`\\c sql_book` or `\\connect sql_book`|  connects to the **ssql_book** database |\n|`\\q` | exits the PostgreSQL session and return to the command-line prompt |\n\nwe also have some commands that are programs installed by PostgreSQL on our system:\n\n| *Command-line Command* | *Notes*|\n|--|--|\n|`psql -d sql_book` | starts a `psql` session and connects to the **sql_book** database|\n|`createdb sql_book` |  creates a new database called **sql_book** using a psql utility|\n| `dropdb my_database` |  permanently deletes the databased named **my_database** and all its data |\n\nRemember that some of the utilities we've shown such as `createdb` and `dropdb` are wrapper functions for actual SQL statements:\n\n| *SQL Statement* | *Notes* |\n|--|--|\n|`CREATE DATABASE sql_book` | creates a new database called `sql_book`|\n|`DROP DATABASE my_database` |  permanently deletes the database named **my_datbase* and all its data|\n\n### DATA TYPES\n\n```\nsql_book=# CREATE TABLE users (\n  id serial UNIQUE NOT NULL,\n  username char(25),\n  enabled boolean DEFAULT TRUE\n  );\n```\n\nThe three columns we created, `id`, `username` and `enabled` were all created with different data types, `serial`, `char(25)`  and `boolean` respectively.  *A data type classifies particular values that are allowed for that column*.  This can helop protect our database from data of an invalid type being entered.\n\nThe table bwlow lists some common data types.  We'll be using a number of these in the rest of the book and you will encounter others as you continue to use SQL.\n\n|*Column Data Type*| *Description* |\n|--|--|\n|serial |  This data type is used to create identifier columns for a PostgreSQL database.  These identifiers are integers, autoincrementing and cannot contain a null value. |\n|char(N)|  This data type specifies the information stored in a column can contain strings of up to N characters in length.  If a string lesss than length N is stored, then the remainng string length is filled with space characters.|\n|varchar(N)| This data type specifies that information stored in a columne can contain strings of up to N characters in lenght.  If a stirng less than length N is stored, then the remaining string length isn't used|\n|boolean| This data type can only contain two values \"true\" or \"false\".  In PostgreSQL, boolean values are often displayed in a shorthand format, t or f|\n|intger or INT| An integer is simply a \"whole number\". An example might be 1 or 50, -50 or 792197 depending on what storage type is used.|\n|decimal(precision, scale)|  The decimal type takes two arguments, one being the total number of digits in the entire number on both sides of the decimal point (the precision) the second is the number of the digitis in the fractional part of the number to the right of the decimal point (the scale).|\n|timestamp | The timestampe type contains both a simple data and time in YYYY-MM-DD HH:MM:SS format.|\n|date | the date type contains a date but no time|\n\n`The use of serial is no longer recommended for new (production) applications.  IDENTITY syntax should be used instead`\n\n\n### Keys and Constraints\n\nWhile data types are a mandatory part of a column defintion, constraints are optional.  THey are extremely useful however, and more often than not you'll want to add some kind of constraints to your columns. \n\nOne of the key functions of a database is to maintain the integerity and quality of the data that it is storing. Keys and Constraints are rules that define what data values are allowed in certain columns.  They are an important database concept and are part of a database's schema definition.  Defining keys and Constraints is part of the database design process and ensures that the data within a database is reliable and maintians its integrity.  Constraints can apply to a specific column, and entire table, more than one table, or an entire schema.\n\nThe creation statement for the `users` table specified some properties, or constraints for each column.  Let's go over those now:\n\n- UNIQUE:  THe `id` column also has a `UNIQUE` constraint, which prevents any duplicate values form being entered into that column. \n- NOT NULL: the `id` colun also has a `NOT NULL` constrain, which essentially means that when adding data to the table a value MUST be specified for this column; it cannot be left empty.\n\n- DEFUALT:  The `enabled` column has an extra property `DEFAULT` with a value of `TRUE` is set in that field. \n\nWe haven't run into keys just yet, but we will later on.  They come into play when we have to set up relationships between database tables.  They're also useful for keeping track of uniqure rows within a database table.  We'l explore keys and contraints in more detail later on. \n\n### View the table\n\n`\\dt` meta-command to show us a list of all the tables, or relations, in the database. \n\nFor more information of the tables we use the `\\d` metacommand \n\n\n- tables are created using the `CREATE TABLE` SQL command\n- Table column definitions go between the parenthese of the table creation statement \n- Table column definitions consist of a column name, a data type, and optional constraints\n- Table columns definitions consist of a column name, a data type, and and optional constraints - There are many different data types, and these can be used to restrict the data that can be input to a column \n- Constraints can also be used on the data that is input to a particular column\n- We can view a list of tables or the structures of a particular table in the psql consule using meta-commands\n- Although database schema is largely a DDL (Data Definition Language) concern, parts of it, such as access and permisisons, are deteremed by DCL (Data Control Language)\n\n| *Command* | *Notes*|\n|Create Table users.. | Creates a new table called **users**|\n|\\dt | Shows the tables in the current database|\n|\\d users | Shows the schema of the table **users**|\n\n\n###Altering Tables\n\n|Action| Command| Notes|\n|--|--|--|\n|Add a column to a table| ALTER TABLE table_name ADD COLUMN column_name data_type CONSTRAINTS; | Alters a table by adding a column with a sepcified data type and optional constraints.|\n|Alter a column's data type| ALTER TABLE table_name ALTER COLUMN column_name TYPE data_type; |\n|Rename a table| ALTER TABLE table_name RENAME TO new_table_name: | Changes the name of a table in the currently connected to database|\n|Rename a columne within a table| ALTER TABLE table_name RENAME COLUMN column_name TO new_column_name; |  Renames a column of the specified table.|\nAdd column constraint (`NOT NULL`)|  ALTER TABLE table_name ALTER COLUMN column_name SET NOT NULL; | Adds a specified constraint to the sepcified table column|\n|Add table constraint|  ALTER TABLE table_name ADD CONSTRAINT constraint_name constraing_clause; | ALTER TABLE films ADD CONSTRAINT title_unique UNIQUE (title)|\n|Remove a table constraing | ALTER TABLE table_name DROP CONSTRAINT constraint_name; | Removes a constraint from the specified table.|\n|Removes a column constraint |  ALTER TABLE table_name ALTER COLUMN column_name DROP CONSTRAINT; |  Removes a constraint form the specified column.  This syntax is necessary for 'NOT NULL' constrains which aren't specifiically named. |\n|Remove a column form a table | ALTER TABLE table_name DROP COLUMN column_name; |  Removes a column from the specified table.|\n|Delete a table from the database|  DROP TABLE table_name; |  Permanently deletes the specified table from its databse.\n\n\n### Data and DML\n\nDML is sub-language of SQL which incorporates the various key words, clauses and syntax used to write Data manipulation statements.\n\nData Manipulation Statements are used for acessing and manipulating data in the database. Data Manipulaiton Statements can be categorized into four different types:\n\n- `INSERT` statements - These add new data into a database table\n- `SELECT` statemetns - ALSO referred to as Queries; these retrieve existing data from database tables.  We've worked with this type a bit already.\n- `UPDATE` statemetns - These update exisiting data in a database table.\n- `DELETE` statements - these delete existing data from a database table. \n\nThe actions performed by these four types of statements are sometimes also referred to as CRUD operations.\n\nThe term `CRUD` is commonly used acronym in the database world.\nTHe leters stand for CREATE, READ UPDATE, and DELETE.  These four words are analogour to our `INSERT`, `SELECT`, `UPDATE` and `DELETE` statements, and we can think of these statemetns as performing their equivalent CRUD operations. Web applications whose main purpose is to provide an interface to perform these operations are often referred to as `CRUD apps`.\n\n#### using DML\n\nWe've covered a  number of different aspects of adding data:\n\n- `INSERT` statement syntax\n- Table rows\n- Adding a single row of data\n- Adding multiple rows of data\n- Various types of constraints we can use to control what dat is added:\n  - `DEFAULT` values\n  - `NOT NULL` constraints\n  - `UNIQUE` constraints\n  - `CHECK` constraints\n  \nmain commands:\n\n|*Command*| *Notes*|\n|--|--|\n|INSERT INTO tabe_name (column1_name, column2_name,...) VALUES (data_for_column1, data_for_column2, ...);| creats a new record in **table_name** with the specified columns and their associated values. |\n|ALTER TABLE table_name ADD UNIQUE (column_name);| Adds a constraint to `table_name` that prevent non-unique values from being added to the table for `column_name`|\n|ALTER TABLE table_name ADD CHECK (expression); |  Adds a constraint to table_name that prevents new rows from being added if they don't pass a `check` based on a specified expression| \n\n\n#### co parisions operators\n\n|Operator |  Description |\n|--|--|\n|`<`| less than|\n|`>` | greater than |\n|`<=` | less than or equal to |\n|`=` | equal|\n|`<>` or `!=` | not equal |\n\nAs well as the comparison operators listed above, there are what is termed **comparison preicates** which behave much as operators but have special synatx. Examples includ; `BETWEEN`, `NOT BETWEEN`, `IS DISTINCT FROM`, `IS NOT DISTINCT FROM`.  We won't dicuss these in this boook, though there are two important ones which we will brielfly cover: `IS NULL` and `IS NOT NULL`.\n\n#### Logical Operators\n\nLogical operators can be used to provide more flexiblity to your expressions.  There are three logical operators:\n\n1. `AND`\n2. `OR`\n3. `NOT`\n\n\n#### SUMMARY of SELECT queries\n\n\n| SELECT Clause | Notes|\n|--|--|\n|ORDER BY column_name [ASC, DESC] | Orders the data selected by a column name within the associated table.  Data can be ordered in descending or ascending order; if neither are specified, the queity defaulst to ascending order.|\n| WHERE column_name [<, =, <=, =, <>] value |  Fileters a query result based ons some commparison between a column's value and a specifired literal value.  THere are several comparison operators available for use from \"greate than\" to \"not equal to\". |\n| WHERE expressions 1 [AND, OR] expression2 |  Filerters a query result based whether one expression is tru [and, or] another expression is true.|\n|WHERE string_column LIKE '%substring' |  Filters a query result based on whether a substring is contained within string_column's data and has a number of characters before that substring.  Those characters are mathed using the wilcard `%`.  `%` doens't have to come before a stubstring, you can also put it after one as well, matching the substring first and then any number of characters after that substring.|\n\n\n\n#### Functions\n\n1. String\n2. Date/Time\n3. Aggregate\n\n####String Functions\n\n|Function| Example | Notes|\n|--|--|--|\n|`lenght` |  `SELECT length(full_name) FROM users;` | This returns the length of very use's name you could also use `length` in a `WHERE` clasue to filter data based on name length. |\n| `trim` | `SELECT trim(leading ' ' from full_name) FROM users;` | If any of the data in our `full_name` column had a space in fornt of the name, using the `trim` function like this would remove that leading space.|\n\n#### Date/Time Functions\n\n|function| example| Notes|\n|--|--|--|\n|`date_part`| `SELECT full_name, date_part('year', last_login) FROM users;`| `date_part` allow us to view a table that only contains a part of a user's itmestamp that we specify.  The above query allows us to see each user's name along with the year of the `last_login` date. Sometimes having date/time data down to the secon isn't needed|\n|`age` | `SELECT full_name, age(last_login) FROM users;` | The `age` function, when passed a single `timestamp` as an argument, calculates the time elapsed between thhat timestamp and the current time.  The above query allows us to see how long it has been since each user last logged in |\n\n#### Aggregate Functions\n\nAggregate functions perform **aggregation;** that is, they compute a single result form a set of input values.  \n|Function | Example | Notes|\n|--|--|--|\n|`count`|`SELECT count(id) FORM users;` | Returns the number of values in the column passed in as an argument.  THis type of function can be very useful dpending on the context.  We could find the number of users who have enabled an account, or even how many users have certain least names if we uswe the above stament with other clauses.|\n|`sum`| `SELECT sum(id) FROM users;` | Not to be confused with `count `. This **sums** numeric type values for all of the selected rows and returns the total. |\n|`min`| `SELECT min(last_login) FROM users;` | This returns the lowest value in a column for all of the selected rows.  Can be used with various data types such as numeric, date/time, and string |\n|`max` | `SELECT max(last_login) FROM users;` | This returns the highest value in a column for all of the selected rows.  Can be used with various data types such as numeric, date/time, and string.|\n|`avg` | `SELECT avg(id) FROM users;` | Returns the average(arithmetic mean) of numeric type values for all of the selected rows|\n\n### UPDATING DATA\n\nAn update statement can be written with the following syntax:\n\n```\nUPDATE table_name SET [column_name1 = value1, ...]\nWHERE (expression);\n```\n\nThis statement can be read as, \"Set column(s) to these values in a table when an expression evaluates to true\".  We can specify any table in our database to update and sepcify any number of columns within that table. \n\nThe `WHERE` caluse is optional.  If omitted, PostgreSQL will update every row in the target table. \n\n#### DELETING DATA\n\nThe `DELETE` statment is used to remove entire rows from a databas table.  The form of a delete statemnt is somewhat similar to `UPDATE`:\n\n```DELETE FROM table_name WHERE (expression); ```\n\nAs with `UPDATE`, the `WHERE` clause in a `DELETE` statment is used to target specific rows.\n\n\n| Statement | Notes |\n|--|--|\n|UPDATE table_name SET [column_name =value1, ..] WHERE (expression); |Update specified fields within a table.  The rows updated are dependent on the `WHERE` clause.  We may update all rows by leaving out the `WHERE` clause.|\n|DELETE FROM table_name WHERE (expression)| Delete rows in the specified table.  Which rows are deleted is dependet on the `WHERE` clause.  We may delete all rows by leaving out the `WHERE` clause. |\n\n### TABLE RELATIONSHIPS\n\n#### Normalization\n\nTHe process of splitting up data in this way to remove duplication and imporve data integrity is nown as **normalization**.\n\nTwo important things to remember about normalization:\n\n- The reason for normalization is to reduce data redundancy and improve data integrity\n- The **Mechanism** for carrying out normalization is arranging data in multiple tables and defining relationshiups between them.\n\n#### Keys\n\nKeys are a special type of constraint used to establish relationships and uniqueness.  They can be used to **identify** a specific row in the current table, or to refere to a specific row in another table.  There are two types of keys that fulfil these particular roles; *Primary Keys*. and *Foriegn Keys.\n\n##### Primary Key\n\n*A Primary Key is a unique identifier for a row of data.*\n\nIn order to act as a unique idetifier, a column must contain some data, and that data should be unique to each row.  \n\n##### FOREIGN Keys\n\nA Foreign Key allows us to associate a row in one table to a row in another table. This is done by setting a column in one table as a Foreign Key and having that column refrence another table's Primary Key column.\n\n````FOREIGN KEY (fk_col_name) REFERENECES target_table_name (pk_col_name)```\n\nTHe specific way in which a Foreign Key is used as part of a table's schema depends on the type of relationshipe we want to define between out tables.  In order to implment that schema correctly it is useful to formally describe the relationships we need to model between our entities:\n\n1.  A User can have *ONE* address.  And address has only *ONE* user.\n2.  A review can only be about *ONE* Book.  A Book can have *MANY review*. \n3.  A User can have *Many* books that he/she may have checked out or returned.  A Book can be/have been checked out by *Many* users.\n\nThe entity relationships described above can be classified into three relationship types:\n\n- one-to-one\n- one-to-many\n- many-to-many\n\n###### one-to-one \nA one-to-one relationship between two entities exists when a particular entity instance exists in one table, and it can have only one associated entity instance in another table. \n\nThis sort of relationship is implemented like this: the `id` that is the `PRIMARY KEY` of the `users` table is used as both the `FOREGIN KEY` and `PRIMARY KEY` of the `addresses` table.\n\n```/*\none-to-one: User has one address\n*/\n\n\nCREATE TABLE addresses (\n  user_id it, -- Both a primary and foreign key\n  strett varchar(3) NOT NULL,\n  city varchar(3) NOT NULL,\n  state varchar(3) NOT NULL,\n  PRIMARY KEY (user_id),\n  FORERIGN KEY (user_id) REFERENECES users (id) ON DELETE CASCADE\n);\n\n```\nThe `PRIMARY KEY` and `FOREIGN KEY` clauses at the end of the `CREATE` statement creat ethe constraints that makes the `user_id` the Primary Key of the `addresses` table and also the Foreign Key for the `users` table.\n\n###### One-to-Many\n\nA one-to-many relationship exists between two entities fi an entity istnace in one of the tables can be assoicate with multiple records (entity instances) in the other table.  The opposite relationship does not exist; that is, each entitiy instance in the second tanble can only be assoicated wtih one entity instance in the first table.\n\n*Example:* A review belongs to only one book.  A book has many reviews.\n\nA many-to-many relationship exists between twon entities if for one entity instnace ther may be mulitple records in the other table, and vice vera.\n\n*Example:*  A user can check out many books.  A book can be checked out by many users (over time). \n\nIn order to implement this sort of relationship we need to intorduce a third, cross-reference, table.  This table holds the relationship between the two entitites,by having *two* `FOREIGN KEY`s, each of which reference the *Primary Key* of one of the tables for which we want to create this relationship.  We already have out `books` and `users` tables, so we just need to create the cross-refernce table: `checkouts`.\n\n![Screen Shot 2020-12-14 at 6.20.36 PM.png](quiver-image-url/7A47968CF5505C10271502EC21AC3974.png =706x195)\n\nHere, the `user_id` column in `checkouts` references the `id` column in `users`, and the `book_id` column in `checkouts` references the `id` column in `books`.  Each row of the `checkouts` table uses these two Foreign Keys to create and assoiciation between rosw of `users` and `books`.\n\n- we briefly covered normalization, and how this is used to reduce redundancy and imporve data integrity within a database.\n- ERDS were introduced and we discussed how these digrams allow us to model the relationships between different entitites.\n- WE also loked at keys and how primary and foreign keys work toegether to crea teh relationships between diffferent tables.\n- FInally we looked at some fo the different types of relationships that can exist between tables and how to implement these with SQL statments. \n\n|*Relationship*| *Example*|\n|--| --|\n|one-to-one| *A* User has *ONE* address|\n|one-to-many|  *A* Book has *MANY* reviews |\n|many-to-many | *A* user has *MANY* books and a book has *MANY* users|\n\n\n### JOINS\n\nThis is used to join multiple tables in a database together.\n\n#### JOIN syntax\n\n```\nSELECT [table_name.column_name1, table_name.column_name2, ..] FROM table_name1 join_type JOIN table_name2 ON (join_condition);\n```\n\nTHe first part:\n\n```\nSELECT [table_name.column_name1, table_name.column_name2, ..] FROM\n```\nis essentially the `SELECT column_list FROM` form that you've already seen in previous `SELECT` queries, with the slight difference that column names are prepended by table names in the column list. \n\nLet's first focus on the second part of the statment, the part that joins the tables:\n\n```\ntable_name1 join_type JOIN table_name2 ON (join_condition)\n```\n\nTo join one table to another, PostgreSQL needs to know several pieces of information:\n\n- The name of the first table to join\n- The type of join to use\n- The name of the second table to join\n- the join condition\n\nThese pieces of information are combined together using the `JOIN` and `ON` keywords. THe part of the statment that comes after the `ON` keyword is the join condition; This defines the logic by which a row in one tbale is joined to a row in another tyable.  IN most cases this join condition is created using the primary key of the obe table and the foreign key to the table we want to join it with. \n\nRemember our `colors` and `shapes` examples form the previous chapter?  The `color_id` column of the `shapes` table is a Foreign Key which references the `id` column of the `colors` table. \n\n![Screen Shot 2020-12-16 at 2.54.56 PM.png](quiver-image-url/06DDCE92154CFCF5208D16F6A4DE529F.png =681x198)\n\nIf we wanted a list of shapes and their colors, we could use a query like this:\n\n```\nSELECT colors.color, shapes.shape FROM\n  colors JOIN shapes ON\n  colors.id\n```\n\nWithin the second part of this query, `colors JOIN shapes ON colors.id = shapes.color_id` The join condition will look at each `id` value in the `colors` table and attempt to match it with a  `color_id` value in the `shapes` table. IF there is a match then those two rows are joined together to form a new row in a virtual table known as a **join table**. Since the `id` `1` for the color `Red` appears twice in the `color_id` column of our `shapes` table, this row of the `colors` table appears twice in our virtual join table, joined to both `Square` and `Star`.  SINCE the `id``3` for the color `Orange` does not appear at all in the `color_id` column of our `shapes` table.  This row of the `colors` table is ommitted completely form our virtual join table. \n\n\n*Shapes_colors_join_table\n\n|colors.id|colors.color|shapes.id|shapes.color_id|shape.shape|\n|--|--|--|--|--|\n|1| 'Red'|1|1|'Square'|\n|1|'Red'|2|1|'Star'|\n|2|'Blue|3|2|'Triangle'|\n|4 |'Green'|4|4|'Circle'|\n\nWith this virtual **join table** created, the `SELECT column_list FROM` part of our statement can then be executed to select columns from this virtual table.  Those columns could originally be from the first table or the second table; to avoid confusion we therfore nee to specify both teh table name and columne name in our column list, in the form `table_name.column_name1`.  Looking at our example, selecing columns from our vitual join table is effectily the same as saying \n\n```SELECT colors.color, shapes.shape FROM shapes_colors_join_table;```\n\n\n#### Types of Joins As mentioned earlier, a `JOIN` statement can come in various forms.  To specify which type of join to use, you can add either `INNER`, `LEFT`, `RIGHT`, `FULL` or `CROSS` just before the keyword `JOIN`.  We'lll look at example of each ot these types of join using the tables in our `sql_book` database.\n\n#####INNER JOIIn\n\nAN `INNER JOIN` returns a result set that contains the common elements fo the tables, i.e the intersection where they match on the joined condition.  INNER JOINS are the most frequently used JOINS; in fact if you don't sepcify a join type and simply use the `JOIN` keyword, then POSTgreSQL will assume you want an inner join.  Our `shapes` and `colors` example from ealirer used an an `INNER JOIN` in this way.\n\nIn the query below, the line `INNER JOIN (addresses) ON (users.id = addresses.user_id)` create sthe intersection between the two tables, which means that the jion table contains only rows where there is a definite match between the values in the two columns used in the condition. \n\n```\nSELECT users.*, addresses.*\nFROM users\nINNER JOIN addresses\nON (users.id = addresses.user_id);\n\n\n```\n\nThe data in our unjoined tables looks like this:\n![Screen Shot 2020-12-16 at 4.36.13 PM.png](quiver-image-url/D28364D209DA343718DAFDAF7AE7CEAD.png =779x170)\n\nTHE result of our `SELECT` query using and `INNER JOIN` would look like this:\n\n![Screen Shot 2020-12-16 at 4.37.24 PM.png](quiver-image-url/5DC4CC91642BCC688A7D63D5D59B24D6.png =748x157)\n\nTHE value in the `id` column of the `users` table for the user `Jane Smith` is `5`; since this value does not appear in the `user_id` of the addressees table, she is omitted entirely form the join table and so only 3 records are returned by the query.\n\nIf we did want to include Jane Smith in our results despite here not having an address, we could have to use a different type of join, and outer join.\n\n###LEFT JOIN\n\nA LEFT JOIN or  LEFT OUT JOIN takes all the rows from one table, defined as the `LEFT` table, and joins it with a second table.  the `JOIN` is based on the conditions supplied in the parentheses.  A `LEFT JOIN` will will always include the rows from the `LEFT` table, even if there are no matching rows in the table it is JOINed with. \n\nLet's try and use the same JOIN query as before, but this time we'll use a left join:\n\n```\nSELECT users.*, addresses.*\nFROM users\nLEFT JOIN addresses\nON (users.id = addresses.user_id);\n```\n\nHere, the `Jane Smith` row form the `users` table is included in the join table, since she doesn't have any macthcing rows in the `addresses` tbale, the join table has `NULL` values in here row for the columns of that table\n\n\n![Screen Shot 2020-12-16 at 4.53.21 PM.png](quiver-image-url/05475004C9B60A214731788C4CE4EF76.png =759x180)\n\nNote that using either `LEFT JOIN` or `lEFT OUTER JOIN` does exactly the same thing, and the `OUTER` part is often omitted. EVEN so, it is still common to refer to this type of join as an 'outer' join in order to differentiate it from an 'inner' join.  Another type of outer join is a `RIGHT JOIN`.\n\n#### RIGHT JOIN\n\nA `RIGHT JOIN` is similar to a `LEFT JOIN` except that the roles between the two tables are reversed and all the rows on the second table are included along with any matching rows form the first table.  IN the last chapter we mentioned that in our `sql_book` database we have books, and also reviews for those books.  Not all of our books have reviews, however. Let's make a `RIGHT JOIN` or `RIGHT OUTER JOIN` that displays all reviews and their associated books, along with any boos that don't have a review.\n\n```\nSELECT reviews.book_id, reviews.rating, reviews.published_date, books.id, books.title, books.author\nFROM reviews RIGHT JOIN books ON (reviews.book_id = books.id);\n\n```\n\nTHe data in our unjoined tables looks like this:\n\n![Screen Shot 2020-12-16 at 5.06.54 PM.png](quiver-image-url/F669777F694F41F00B9EADEA8CFD27B7.png =656x318)\n\nThe result of our `SELECT` query using an `RIGHT JOIN` would look like this:\n\n![Screen Shot 2020-12-16 at 5.07.44 PM.png](quiver-image-url/94588DFE477CE13101F3C4B75067C4F5.png =783x189)\n\n\nAs you can see, `My Third SQL Book` doesn't yet have a review, and so all the columns from the review table have `NULL` values for the row in the join table. \n\n###FULL JOIN\n\nA `FULL JOIN` or `FULL OUTER JOIN` is essentially a combination of `LEFT JOIN` and `RIGHT JOIN`.  THIS type of join contains all of the rows from both of the tables.  Where the join condition is met, the rows of the two tables are joined, just as in the previous examples we've seen.  For any rows on either side of the join where the join condition is not met, the columns for the ohter table have `NULL` values for that row.\n\nA `FULL JOIN` is a little less common than the other ones we've looked at so far and so we won't show an example for this.  \n\nAnother uncommon type of join is a  `CROSS JOIN`; let's take a look.\n\n#### CROSS JOIN\n\nA `CROSS JOIN`, also known as a Cartesian JOIN, returns all rows from one table crossed with every row from the second table.  In other words, the join table of a cross join contains every possible combination of rows from the tables that have been joined.  Since it returns all combinations, a `CROSS JOIN` does not need to match rows using a join condition, therefore it does not have an `ON` clause.\n\nThe way this join works is sometimes a little difficult to envisage, so it's worth looking at an example in this case.  THis SQL query has the similar syntax to other `JOIN`s, but wihtou the `ON` clause:\n\n```\nsql_book=# SELECT * FROM users CROSS JOIN addresses;\n```\nThe query above returns the `addresses` and `users` tables, cross joined.  This result consists of every record in `users` mapped to every record in `addresses`.  For 4 users and 3 addresses, we get a total of `4x3=12` records.  In mathematical terms, this is the **cross product** of a set.\n\nCross Join Between Users and Addresses:\n\n![Screen Shot 2020-12-17 at 11.14.57 AM.png](quiver-image-url/F993B6C4CF12C7040229E15E85BEB363.png =746x428)\n\nIn an application, it's very unlikely that you would use a  `CROSS JOIN`.  Most of the time, it's more important to match rows together through a join condition in order to return a meaningful result.  It's sill importnat to be aware of `CROSS JOIN` however, since you may occasionally encounter them.\n\n### Mulitple Joins\n\nIt is possible, and indeed common, to join more than just two tables together.  This is done by adding addition `JOIN` clauses to your `SELECT` statment.  To join multiple tables in this way, there must be a logical relationship between the tables involved.  One example would be joining our `users`, `checkouts`, and `books` tables.\n\n```\nSELECT users.full_name, books.title, checouts.checkout_date\nFROM users\nINNER JOIN checkouts ON (users.id = checkouts.user_id)\nINNER JOIN books ON (books.id = checkouts.book_id);\n```\nHere we are using two `INNER JOIN`s.  ONe between `users` and `checkouts` and one between `books` and checkouts.  In both cases the `JOIN` is implemented by using the Primary Key of one table (either `users` or `books`) and the Foreign Key for the table in the `checkouts` table. \n\n\n#### Aliasing \n\nYou may have noticed that some of the queries we list above can get a bit long. We can cut back on the lenght of these queires by using aliasing.  Aliasing allows us to sepcify another name for a column or table and then use that name in the later parts of a query to allow for more concise syntax.  Let's use our three table join from above as an example. Using aliasing, the query would look like this:\n\n```\nSELECT u.full_name, b.title, c.checkout_date\nFROM users AS u\nINNER JOIN checkouts AS c ON (u.id = c.user_id)\nINNER JOIN books As b ON (b.id = c.book_id);\n```\n\nHere we specify single letter aliases for our tables, and use those aliases instead of our table names in order to prepend the columns from those tables in the column list and in the join conditions.  This is commonly referred to as 'table aliasing'. \n\nWe can even us a shorthand for aliasign by leaving out the `AS` keyword entirely `FROM users u` and `FROM users AS u` are equivalent SQL clauses. \n\n####Column Aliasing\n\nAlising isn't just useful for shrotening SQL quereies.  We can also use it to display more meaningful informaiton in our results table.  For instance, if we wnat to display the number of checkouts from the library we could write something like:\n\n```\nsql_book=# SELECT count(id) AS \"Number of Books Checked Out\"\nsql_book-# FROM checkouts;\nNumber of Books Checked Out\n-------------------\n                4\n(1 row)\n```\nIF you're a user just trying to access information, then most likely you wouldn't know about the exact tables being queried; being explicit about what information we're displaying can be important in a case like that. \n\n#### Sub quereies\n\nThus far in this chapter, we've looked at using `JOIN`s to work with more than one table.  Although joining tables together is probably the most comon way of working with mulitple tables, you can often achieve the same results through use of a subquery. Before we compare subqueires and joins, let's examine what a subquery is.\n\nImagine exectuing a `SELECT` query, and then using the result sof that SELECT query as a condition in **another** `SELECT` query. This is called nesting, and the query that is nested is rferred to as a *subquery*.\n\nFor example, suppose we need to select users that have no books checked out.  We could do this by finding `users` whose `user_id` is not in the `checkouts` table.  If no relation is found, that could mean that the user has not checked out any books. \n\n```\nsql_book# SELECT u.full_name FROM users u\nsql_book-# WHERE u.id NOT IN (SELECT c.user_id FROM checkouts c);\n  full_name\n-------------\n  Harry Potter\n(1 row)\n```\n\nIn the code above, the `NOT IN` clause compares the current `user_id` to all of the rows in the result of the subquery.  If that `id` number isn't part of the subquery results, then the `full_name` for current row is added to the result set. \n\nThis might seem a bit confusing, so let's break it down.  Our initial checkouts table look like this:\n\n![Screen Shot 2020-12-17 at 11.51.16 AM.png](quiver-image-url/7DB62479BA6B5A7EAE35C8042010BB47.png =664x200)\n\nThe nested query `SELECT c.user_id FROM checkouts c` returns the following results:\n\n![Screen Shot 2020-12-17 at 11.52.05 AM.png](quiver-image-url/34166B72531B5374BCB88272F1D988F4.png =196x152)\n\nThis virtual table can then effectivley be used by our `NOT IN` clause as a list of values against which to check the values in the `id` columne of our `users` table.\n\n![Screen Shot 2020-12-17 at 11.55.05 AM.png](quiver-image-url/02FE448B10C3FD07747E862C05CD1B8B.png =851x182)\n\nThe only value in that column that is *not in* the results of the nested query is the `id` for 'Harry Potter': `3`. \n\n*Subquery Expressions*\n\nPostgreSQL provies a number of expressions that can be used specifically wiht sub-queries such as `IN`, `NOT IN`, `ANY`, `SOME` and `ALL`.  These all work slightly differently, but essentially they all compare values to the results of a subquery.\n\n#### Sub quries vs JOINS\n\nAs you write more queries, you may find that there is more than one way to write a query and achieve the same results.  The most common choices are betwen subqueries and JOINs.\n\nFor instance, we can get the same result table as in our previous example by using a  `JOIN` clause istead of a subquery.\n\n```\nSELECT u.full_name FROM users u\nLEFT JOIN checkouts c ON (u.id = c.user_id)\nWHERE c.user_id IS NULL;\nfull_name\n------------\nHarry Potter\n(1 row)\n```\nWhen creating queries that return the same resul, a differentiator between them may be their perfromance when compare to each other.  As a general rule, JOINS are faster to run than subqueries.  THis may be something to bear in mind if working with large datasets. \n\none of the most important things to remember baout *how joins work* is that we set a condition that compares a value from the first table (usually a primary key), with one from the second table (usually a foreign key).  If that condition that uses these two values evaluates to true, then the row that holds the first value is joined with the row that holds the second value. \n\nLet's quickly recap on some of the different *types of join* we can use:\n\n|*Join Type*| *Notes*|\n|--|--|\n|INNER| combines rwos form two tables whenever the join condition is met.|\n|LEF| Same as an inner join, except rows from the first table are added to the join table, regardless of the evaluation fo the join condition|\n|RIGHT| same as an inner join, except rows form the second table are added to the join table, regardless of the evaluation of the join coniditon|\n|FULL| A combination of left jion and right join.|\n|CROSS| Doesn't use a join condition.  THe join table is the result of matching every row from the first table with the second table, the cross prdocut of all rows across both tables.|\n\nWhen using joins, sometimes our queries cna get unwiedly, expecially when we're dealing with 2 or more `JOIN`s.  To better manage this we can *alias* table and column names to shorten our query.  We can also use aliasing to give more context about the query results. \n\nFinally, the result form a join query can somteims be obtained using different methods.  *Subquereies* offere naother method for us to query the database and retrieve the same results of similar results, as if we had used a JOIN clause.\n\n\n###SUMMARY\n\nOur main goal in this book was to introduce you to the SQL language and to get you reay for the next course.\n\n####getting started\n\nwe started off looking at things from a conceptual level, talking about why data is important, comparing unstructured and structured data, and finally explainin ghow databases, RDBMSes, and SQL fit into the picture.\n\nFor some of you this may have bene the first time using a RDBMS and possiblye even SQL.  AS a primper to get started with SWL SOMe initila vocab was intorudced, installlation instructions for POSTgreSQL wre provided, and we expolored the idea of **connecitng to a database** and looked at different ways of interacting with PostgreSQL.  We then worked thorugh a brief tutorial to give you a tastse of what SQL can do.\n\n###Schema\n\nWe then moved on to the concept of database **schema**, looking at how to create a database and the tables within it.  We listed some `psql` console meta-commands and then fouces on using `CREATE`, `ALTER`, and `DROP` SWL statemetns to create or change a schema.  As part of our dicussion on schema we talked here about various data types and introduced the important topic of keys and constraints.\n\n###DATA\n\nAn importnat take-away form the section on schema is the wayin which schema works to determine the **data** we can have in our database tables.  This data part of the puzzle is what we focused on in the 'Your First Database: Data' seciton of the book, epxloring the CRUD operaitons which are caried out usign `INSERT`, `SELECT`, `UPDATE`, and `DELETE`.\n\n#### META COMMAND TABLE\n\n|*Meta Command*| *Description* | *Example*|\n|--|--|--|\n|`\\c $dbname` | Connect to database `$dbname`. | \\c blog_development|\n|\\d | Describe available relations | |\n|\\d $name | Describe relation $name | \\d users|\n|\\? | List of console commands and options | |\n|\\h| List of available SQL syntax Help topics | |\n|\\h | list of availabel SQL syntax Helop tocpis ||\n|\\h $topic | SQL syntax Help on syntax for $topic | \\h INsert|\n|\\q| QUIT | | \n\n\n###PostgreSQL Data Types\n\nWhile PostgreSQL (and most database systmes) support a large number of data types, we will focus on the following types in this course:\n\n\n| *Data Type* | *Type* | *Value* | *Example Values* |\n|--|--|--|--|\n|`varchar(length)` | character | up to `length` characters of text | `canoe`|\n|`text`| character | unlimited length of text | `a long string of text`|\n|`integer`| numeric | whole numbers | `42`, `-1423290`|\n|`real` | numeric | floating-point numbers | `24.563`, `-14924.3515`|\n|`decimal(precision, scale)` | numeric | arbitrary precision numbers | `123.45`, `-567.89`|\n|`timestampe` | datae/time | date and time | `1999-01-08 04:05:06` |\n|`date` | date/time | only a date | `1999-01-08` |\n| `boolean` | boolean | true or false | `true`, `false` |\n\nTHe names used above (and the ones used throughout this course) are the PostgreSQL-recommended names from its main documentation.  Many of the types have alternate names that come from on of the SQL stnadards or one of the other SQL servers.\n\nOne alternate type name you'll see a lot of in this course is `numeric`, which is an alias for the `decimal` data type.  In the future you will probably use one of the other RDBMSs, and at that time, you may need to look up the other equivalents ot the types used in this course.\n\nIts important to keep in mind that most data types have a limit to the amount of data they can store.  For example an `integer` column can only store integer values between -2147483648 and +2147483647.  Other data types, such as `varchar`, have a limit that is defined by the column. PostgreSQL will return and error if you attempt to store too large a value in a column. \n#### NULL\n\nThere is a special value in relational databases called *NULL*.  This value represents nothing, that is, the absence of any other value.  The crucial thing to rememebr tabout NULL is that it behaves somewhat differently than the nothing value in other languages.  Most languages have something similar to `NULL`, and you can compare that value to itselef to get a truthy result. For example:\n\n```javascript\n#Javascript\n\nnode\nnull == null\n= true\n```\n\n```ruby\n#ruby\n\nirb\nnil == nil\n= true \n```\n\n```Python\npython\nNone == None\n= True\n```\nIn SQL, however, `NULL` behaves differently:\n\n```\nsql-course=# SELECT NULL = NULL;\n?column?\n-------------\n\n(1 row)\n```\n\n\nWhen a `NULL` value appears to either side of an ordinary comparision operator (such as `=`, `<`, `>=`, etc.), the operator wil return `NULL` instead of `true` or `false`.The empty output for the previous statment was an example of how `psql` displays NULL values:\n\n```\nsql-course=# SELECT NULL;\n?column?\n--------------\n\n(1 row)\n```\n\nWhen dealing with `NULL` values, *always* use the `IS NULL` or `IS NOT NULL` constructs:\n\n```\nsql-coures=# SELECT NULL is NULL;\n?column?\n-------------\nt\n(1 row)\n\nsql-course =# SELECT NULL IS NOT NULL;\n?column?\n-----------------\nf\n(1 row)\n\n```\n\nCREATE TABLE people(\n  name: varchar(255),\n  age: integer,\n  occupation: 255\n)\n\nINSERT INTO people(name, age, occupation)\nVALUES('ABBY', 34, biologist),\n('Mu''nisah', 26),\n(Mirabelle, 40, contractor)\n\n\n###NOT NULL and Defualt VALUES\n\nThe columns in the tables we've worked with so far have been pretty simple.  Other than specifying a data type and in a few cases, a lengthy, they will accept nearly any value that will fit inside them.\n\nTHe design of relational databases, and truthfully their power comes from the work invovled in defining a common set of attributes (the values of which are are stored in columns).  It follows that the more specific and exact the design of the shcema is, the \"neater\" and more consistent the data will be.  Relational databases allow a schema designer to build a variety of rules about the data into the system.  These rules allow users of the system to make certain asssumptions about the data that lead to simpler solutions.  Let's lok at an example.\n\nLet's say a business keeps some of a businesss's employee data in a stable called employreees:\n\n```\nCREATE TABLE employees (\n  first_name character varying(100),\n  last_name character varying(100),\n  department character varying(100),\n  vacation_remaining integer\n);\n\n```\n\nANd let's add a few employees to the system:\n\n```\nINSERT INTO employees VALUES ('Lenoardo', 'Ferreira', 'finance', 14);\nINSERT INTO employees VALUES ('Sara', 'Mikaelsen', 'operations', 14);\nINSERT INTO employees VALUES ('Lian', 'Ma', 'marketing', 13);\n```\nSo now the **employees** table looks like this:\n\n```\nsql-course=# SELECT * FROM employees;\n\n first_name | last_name | department | vacation_remaining\n------------+-----------+------------+--------------------\n Leonardo   | Ferreira  | finance    |                 14\n Sara       | Mikaelsen | operations |                 14\n Lian       | Ma        | marketing  |                 13\n(3 rows)\n\n```\n\nNow, let' say there is a new employee that has just been hired. We'l add them with this SQL statement:\n\n```\nINSERT INTO employees (first_name, last_name) VALUES('Haiden', 'Smith');\n```\n\nAs a result, the data for this user in the database only includes their first and last names:\n\n```\nsql-course=# SELECT * FROM employees;\n first_name | last_name | department | vacation_remaining\n------------+-----------+------------+--------------------\n Leonardo   | Ferreira  | finance    |                 14\n Sara       | Mikaelsen | operations |                 14\n Lian       | Ma        | marketing  |                 13\n Haiden     | Smith     |            |\n(4 rows)\n\n```\n\nNote that the two NULL values in the last row for the `department` and `vacation_remaining` columns.  On the surface, this looks innocuous enough, and in a way it reflects the fact that they are not yet an active employee that has been assigned a department and vacation time. \n\nThe danger from this scenario and many others like it lies in the behavior of NULL values.  You may recall that NULL is technically an *unknown* value, and this means that its behavior in a variety of situations is also unknown. Let's look at a few examples.\n\nFirst, let's say that the HR department is running a report on users with the largest number of vacation days, perhpas as part of a new strategy to try to encourage these empoloyees to take advantage of their time off.  Someone working on that project might execute a quelity lke this one with the intention of getting back the list of people with the most accumulated vacation:\n\n```\nSELECT * FROM employees ORDER BY vacation_remaining DESC;\n```\nBut when this statement is executed against the current data in the `employees` table, the result may be a bit surprising:\n\n```\nsql-course=# SELECT * FROM employees ORDER BY vacation_remaining DESC;\n first_name | last_name | department | vacation_remaining\n------------+-----------+------------+--------------------\n Haiden     | Smith     |            |\n Leonardo   | Ferreira  | finance    |                 14\n Sara       | Mikaelsen | operations |                 14\n Lian       | Ma        | marketing  |                 13\n(4 rows)\n\n```\n\nAs you can see, the new employee, who happens to have no vacation remaining at all, appears at the top of the list.  This is because NULL values sort to the top.  WHY?  THe position is a bit arbitrary, but remember that the effect of using any operator on a NULL value returns NULL.  This makes it impossible to compare a NULL value with any other value, which is normally how a set of values would be sorted.\n\nBecuase of this arbitrary ordering, NULL values will display first or last.  In PostgreSQL, they appear first when you specify a descending order, and last when you specify a ascending order.\n\nWe'll look at how to fix this problem shortly, but let's go one step further with this example.  Let's imagine that the same company was preparing to pay its employees for the vacation they failed to take during the past year, and as a result, another query was run to figure out how much each employee should be paid: \n\n```\nSELECT *, vacation_remaining * 15.50  * 8 AS amount FROM employees ORDER BY vacation_remaining DESC;\n\n```\n\n```\n first_name | last_name | department | vacation_remaining | amount\n------------+-----------+------------+--------------------+---------\n Haiden     | Smith     |            |                    |\n Leonardo   | Ferreira  | finance    |                 14 | 1736.00\n Sara       | Mikaelsen | operations |                 14 | 1736.00\n Lian       | Ma        | marketing  |                 13 | 1612.00\n(4 rows)\n```\n\nNotice that now there is an additional NULL value in the `amount` column of the result for the new employee.  What would happen if these results were being fed into the payrool system so that paychecks for these values could be created? Hopefully the payrool system was designed to handle this case, but if it was not?  It's possible that it might attempt to creat a transaction at the company's bank to transfer an undefined amount of pay into the employee's account.\n\nNow, most real payrool systems would notice that the first employee had an empty value and ignore that row, but at the same time, notice how an empty value in one column of a database affected not only queries done to that system, but also other systems that have to operate on the same data. \n\nThus, having undefined values, or NULLs, in a database can lead to problems. These issues can manifest themselves in the form of slightly more coplicated queries or as addditional complexity in other systmes that have to be designed to test for every possible value that could be missing. \n\nA better way is to only allow NULL values in the database when they are absolutley needed.  Most of the time, there is another value that can be used instead that can prevent the kinds of complications we've been looking at.\n\nWe can add a rule to the column that requires that it hold a known value of the correct data type:\n\n```\nsql-course=# ALTER TABLE employees ALTER COLUMN vacation_remaining SET NOT NULL;\nERROR:  column \"vacation_remaining\" contains null values\n```\n\nWhoops, we van't make a NOT NULL if it already contains NULL values.  We cna fix this by deleting the problematic rows:\n\n```\nsql-course=# DELETE FROM employees WHERE vacation_remaining IS NULL;\nDELETE 1\n```\n\nNow, let's try again:\n\n```\nsql-course=# ALTER TABLE employees ALTER COLUMN vacation_remaining SET NOT NULL;\nALTER TABLE\n```\n\nWith that restriction in place, if we try to add an employee wihtout specifying a value for `vacatio_remaining`, the database will reject the insert:\n\n```\nsql-course=# INSERT INTO employees (first_name, last_name) VALUES ('Haiden', 'Smith');\nERROR:  null value in column \"vacation_remaining\" violates not-null constraint\nDETAIL:  Failing row contains (Haiden, Smith, null, null).\n```\n\nThe error message from PostgreSQL explains that there is a `not-null constraint` preventing us from sotring a NULL in the `vacation_remaining` column.  We could just provide a value for this column in the query:\n\n```\nINSERT INTO employees (first_name, last_name, vacation_remaining) VALUEs ('Haiden', 'Smith', 0);\n```\n\nBut a better way to handle this situation is to define a *default value* for the column:\n\n```\nALTER TABLE employees ALTER COLUMN vacation_remaining SET DEFAULT 0;\n```\n\nNow, if we attempt to create a row without providing a value for `vacataion_remaining`, the database will use `0` as the value for the column:\n\n```\nsql-course=# INSERT INTO employees (first_name, last_name) VALUES ('Haiden', 'Smith');\nINSERT 0 1\nsql-course=# SELECT * FROM employees;\n first_name | last_name | department | vacation_remaining\n------------+-----------+------------+--------------------\n Leonardo   | Ferreira  | finance    |                 14\n Sara       | Mikaelsen | operations |                 14\n Lian       | Ma        | marketing  |                 13\n Haiden     | Smith     |            |                  0\n(4 rows)\n```\n\nIf we check back on the two querires that were not showing the desired behavior before, they both now return the results that were originally expected:  \n\n```\nsql-course=# SELECT * FROM employees ORDER BY vacation_remaining DESC;\n first_name | last_name | department | vacation_remaining\n------------+-----------+------------+--------------------\n Leonardo   | Ferreira  | finance    |                 14\n Sara       | Mikaelsen | operations |                 14\n Lian       | Ma        | marketing  |                 13\n Haiden     | Smith     |            |                  0\n(4 rows)\n```\n\n```\nsql-course=# SELECT *, vacation_remaining * 15.50 * 8 AS amount FROM employees ORDER BY vacation_remaining DESC;\n first_name | last_name | department | vacation_remaining | amount\n------------+-----------+------------+--------------------+---------\n Leonardo   | Ferreira  | finance    |                 14 | 1736.00\n Sara       | Mikaelsen | operations |                 14 | 1736.00\n Lian       | Ma        | marketing  |                 13 | 1612.00\n Haiden     | Smith     |            |                  0 |    0.00\n(4 rows)\n```\n\nNOT NULL is one of several constraints available that help make a database schema as precise and protective as possible.\n\n### RECREATE TABLE STRUCTURE AND DATA WITH PSQL COMMANDS\n\nWhat PostgreSQL program can be used to create a SQL file that contains the SQL commands needed to recreate the current structure and data of the *weather* table?\n\n```\npg_dump -d sql-course -t weather --inserts > dump.sql\n```\n\nIf you leave off the `--inserts` argument to the `pg_dump`, the resulting SQL statments will still restore the table and its data.  The format will just be slightly different, using a `COPY FROM stdin` statment instead of mulitple `INSERT statments: \n\n```\nCOPY weather (date, low, high, rainfall) FROM stdin;\n2016-03-07  29  32  0.000\n2016-03-08  23  31  0.000\n2016-03-09  17  28  0.000\n2016-03-01  34  43  0.117\n2016-03-02  32  44  0.117\n2016-03-03  31  47  0.156\n2016-03-04  33  42  0.078\n2016-03-05  39  46  0.273\n2016-03-06  32  43  0.078\n\\.\n```\n`COPY FROM` is the default for a reason (it is more effieicent on large data sets), but using `INSERTS` is also valid and creates SQL statements that are typically the same as those that a user of the database might write themselves when adding data to the table manually.\n\n\n### Solving the Problem: Keys\n\nThe solution to this problem is to stop using values witbin the data to identify rows. Or at least, stop using values that have not been carefully selected to be unique across the entire dataset.\n\nSQL databases provide something called keys that solve this problme.  A *key* uniquely identifies a single row in a database table. There are two types of keys that we'll cover in this course: \n\n- Natural Keys\n- Surrogate key\n\n### Natural Keys\n\nA *natural* key is an existing value in a dataset that can be used to uniquely identify each row of data in that dataset.  On the surface there appear to be a lot of values that might be satisfactory for this use: a person's phone number, email address, social security number, or a product number.\n\nHowever, in reality most values that **seem** like they are good candidates for natural keys turn out to not be.  A phone number and email address can change hands.  A social security number shouldn't change but only some people have them.  And products often go through multiple revisions while retaining the same product number.\n\nThere are a varity of solutions to these problems, including using more than one existing value together as a *composite key*.  But instead of solving the problmes associated with natural keys, this will often just defer the problem until later without actually addresing it. \n\n### Surrogate Keys\n\nA *surrogate key* is a value that is created solely for the purpose of identifying a row of data in a database table.  Because it is created specifically for that purpose, it can avoid many of the problems associated with natural keys. \n\nPerhaps the most common surrogate key in use today is an auto-incrementing integer.  This is a value that is added to each row in a table as it is create.  With each row this value increases in order to remain unique in each row. \n\nLet's create a table with just such a column in PostgreSQL:\n\n```\nCREATE TABLE colors (id serial, name text);\n```\n\nIt's common to call the surrogate key created for a table *id*(short of **identifier**).\n\nIt turns out the *serial* columns in PostgreSQL are actually a short-hand for a column definition that is much longer:\n\n```\n--- This statement: ---\nCREATE TABLE colors (id serial, name text);\n\n-- is actually interpreted as if it were this one: \nCREATE SEQUENCE colors_id_seq;\nCREATE TABLE colors (\n  id integer NOT NULL DEFAULT nextval('colors_id_seq'),\n  name text\n);\n```\n\nA *sequence* is a special kind of relation that generates a series of numbers.  A sequence will remember the last number it generated, so it will generate numbers in a predeteremined sequence automatically.\n\nYou can see form the expanded example above that the sequence's value is used as the `id` column's default value.  The next value of a sequence is accessed using `nextval` and can be done in any SQL stament:\n\n```\nsql-course=# SELECT nextval('colors_id_seq');\n nextval\n---------\n       4\n(1 row)\n\n```\n\nONce a number is returned by `nextval` for a standard sequence, it will not be returned again, regardless of whether the value was stored in a row or not.  If we insert another row into the *colors* table, the `id` value for the row will skip `4` and move on to the next value in the sequence:\n\n```\nsql-course=# INSERT INTO colors (name) VALUES ('yellow');\nINSERT 0 1\nsql-course=# SELECT * FROM colors;\n id |  name\n----+--------\n  1 | red\n  2 | green\n  3 | blue\n  5 | yellow\n(4 rows)\n```\n\n####Enforcing Uniquenesss\n\nThere is on potential problem with the *colors* table we've been working with so far, and it has to do with ensuring the values in the `id` column are unique.  This is a requirement of using the column as a key - if there are duplicate values then the column stops being able to uniquely indentify a single row:\n\n```\nsql-course=# INSERT INTO colors (id, name) VALUES (3, 'orange');\nINSERT 0 1\nsql-course=# SELECT * FROM colors;\n id |  name\n----+--------\n  1 | red\n  2 | green\n  3 | blue\n  5 | yellow\n  3 | orange\n(5 rows)\n```\nin a previous section we learned about `UNIQUE` constraints.  Let's add on of those to the *colors* table:\n\n```\nsql-course=# ALTER TABLE colors ADD CONSTRAINT id_unique UNIQUE (id);\n\nERROR: could not create unique index \"id_unique\"\nDETAIL: Key (id)=(3) is duplicated.\n```\n\nOK, let's fix the id for `orange` and then add the constraint:\n\n```\nsql-course=# UPDATE colors SET id = nextval('colors_id_seq') WHERE name = 'orange';\nUPDATE 1\nsql-course=# ALTER TABLE colors ADD CONSTRAINT id_unique UNIQUE (id);\nALTER TABLE\nsql-course=# SELECT * FROM colors;\n\n id |  name\n----+--------\n  1 | red\n  2 | green\n  3 | blue\n  5 | yellow\n  6 | orange\n(5 rows)\n```\n\nNOw we can be assured that the values in the `id` column are unique:\n\n```\nsql-course=# INSERT INTO colors (id, name) VALUES (3, 'purple'); \nERROR: duplicate key value violates unique constraint \"id_unique\"\nDETAIL: Key (id)=(3) already exists\n```\n\nAnd adding a row wihtout attempting to assign an `id` will still use the sequeence to automatically fill in that value:\n\n```\nsql-course=# INSERT INTO colors (name) VALUES ('purple');\nINSERT 0 1\nsql-course=# SELECT * FROM colors;\n id |  name\n----+--------\n  1 | red\n  2 | green\n  3 | blue\n  5 | yellow\n  6 | orange\n  7 | purple\n(6 rows)\n```\n\n### PRIMARY KEYS\n\njust as using `serial` is a shortcut for creating columns with a default auto-incrementing value, PostgreSQL has another shortcut for creating columns that uniquely identify the rows in a table.\n\n```\nCREATE TABLE more_colors (id int PRIMARY KEY, naem text);\n```\n\nBy specifying the `PRIMARY KEY` (in a similar way to how we would specify `NOT NULL`), PostgreSQL will creat an index on that column that enforeces it holding unique values in addition to preventing the column from holding NULL values.  FOr the most part, the above code is the same as:\n\n```\nCREATE TABLE more_colors (id int NOT NULL UNIQUE, name text);\n```\nThe difference between the two is documenting your intention as a database designer.  By using `PRIMARY KEY`, the fact that a certain column can be relied upon as a way to identify specific rows is backed into the table's schema.\n\n```\nNot that, though `PRIMARY KEY` is effectively the same as having both `NOT NULL` and `UNIQUE` constraints, the `PRIMARY KEY` does not **require** those constraints.  In particular, if you want ot change an existing columne to a `PRIMARY KEY`, you don't have to add the `NOT NULL` and `UNIQUE` constraints first -- all that is required is that the column contains unquie values, none of which are `NULL`.\n```\n\nFollowing conventions in software development saves time, reduces confusion, and minimizes the amount of time needed to get up to speend on a new project.  Different teams, and software packages may have varying conventions but contemporary database development within the Ruby, JavaScript, and other communities has sttled on the following conventions for working with tables and primary keys:\n\n1.  All table should have a prmary key column called `id`.\n2.  The `id` column should automatically be set to a unique value as new rows are inserted into the table. \n3.  The `id` column will often be an integer, but ther are other data types (such as UUIDs) that can provide specific benefits.\n\nDo you have to declare a column as a `PRIMARY KEY` in every table?  Techincally, no.  But doing generally a good idea.\n\n\n##### what is a UUID?\n\nUUIDS (or universally unique identifiers) are very large numbers that are used to identify individual objts or when working with database, rows in a database.  There are a few formats and different ways to generate these numbers (they don't increment by 1 as we've been doing).  UUIDs are often represented using hexadecimal strings with dashes such as `f47ac10b-58cc-4372-a567-0e02b2c3d479`.\n\nIf you run into UUIDS somwhere, remember that they are just really large numbers that are used to identify something uniquely.\n\n\n### A Delcarartive language \n\nSQL is a declarative language.  A SQL statement describes **what** to do, but, not how to do it.  It is up to PostgreSQL server to take each query, determine how to best execute it, and return the desired results.\n\nThe beneift of this approach is that it vastly simplifies database interactions for a user.  Databases can perform involved dta manipulations with the use of just a few SQL terms, freeing the user to think at higher level about what data they want returned and in what format.\n\nthe downside to this automated approach is that some of the time, the dtabase will chosse to do something in an inefficient way.  This happens because the only way to know for sure how long a particular query plan will take to execute is to execute it.  The estimates that are generated as a part of the query plan are generally pretty accurate, but when they are off, the result can make processijng a query take much more time and resources than it might otherwise.\n\nFortunately, there a ways to give the database hints (or requiremnets) about how it should execute a query.  For the types of queries we're working wiht in this course, there won't be a need to work with most of these techniques.\n\nWe will talk about indexes in a future assignment.  Query and database optimization is a deep topic that is otherwise beyond the scope of this course. \n\n### How PostgreSQL Executes a Query\n\nWhile the exact way that a PostgreSQL database server will execute a query will depend on many variabls, there is a high-level process that each query goes thorugh.  Being familiar with these steps can be a benefit for knowing the difference between two queries that appear to return the same results, or understanidng why some queires are rejected by the database.\n\nThe basic process for a `SELECT` query is described blow.  Other queries us many of the same steps, but it's not important for you to understand them at this level as they rarely are as complex as `SELECT` queries can be.\n\n#### Rows are collected in a virtual derived table\n\nYou can think of this step as the database creating a new temporary table using the data from all the tables listed in the query's `FROM` clause.  This includes tables that are used in `JOIN` clauses.\n\n#### Rows are filtered using `WHERE` conditions\n\nAll the conditions in the `WHERE` clause are evaluated for each row, and those that don't meet these requirements are removed.\n\n#### Rows are divided into groups\n \nIf the query includes a `GROUP BY` clause, the remaining rows are divided into the appropriate groups. \n\n#### Groups are filtered using `HAVING` condition \n\n`HAVING` conditions are very similar to `WHERE` conditions, only they are applied to the values that are used to create groups and not individual rows.  This means that a column that is mention in a `HAVING` clasue should almost always appear in a `GROUP BY` clause and/or an aggregate function in the same query.  Both `GROUP BY` and aggregate functions pefrom grouping, and the `HAVING` clause is used to filter that aggregated/grouped data.\n\n`HAVING` clauses aren't as common as `WHERE` clauses, and we won't be seeing them very much in this course.\n\n#### Compute values to return using select list\n\nEach element in the select list is evaluated, including any funcitons, and the resulitng values are associated with the name of the column they are from or the name of the last function evaluated, unless a different name is specified in the query with `AS`.\n\n#### Sort Results\n\nthe result set is sorted as specified in an `ORDER BY` clause.  Without this clause, the results are returned in an order that is the result of how the database executed the query and the rows' order in the original tables.  It's best to always specify an explicit order if your application relies on rows being returend in a specific order.\n\n#### Limit Results\n\nIf `LIMIT` or `OFFSET` clauses are included in the query, these are used to adjust which rows in the result set are returend. \n \n#### Schema, Data, and SQL summary \n\n\n- **SQL** is a **special-purpose, declarative*** language used to manipulate the structure and values of datasets stored in a relational databse.\n- SQL is comprised of three sublangauges:\n\n|*sub-language*|*controls*|*SQL Constructs*|\n|--|--|--|\n|*DDL* or data definition lanagage | relation stucture and rules | `CREATE`, `DROP`, `ALTER`|\n|*DML* or data manipulation language | values stored within relations | `SELECT`, `INSERT`, `UPDATE`, `DELETE` |\n|**DCL** or data control lanaguage | who can do what | `GRANT`|\n\n- SQL code is made up of statments, which must be terminated by a semicolon.\n- PostgreSQL provides many data types.  We've looked at the following subsets of types it supports in this lesson:\n\n\n|*Data Type* | *Type* | *Value* | *Example Values*|\n|--|--|--|--|\n|`varhcar(length)` | character| up to `length` characters of text | `canoe`|\n|`text` | character | unlimited length of text | ` a long string of text` |\n|`integer` | numeric | whole numbers | `42`, `-1423290`|\n|`real` | numeric | floating-point numbers | `24.563`, `-14924.3515`|\n|`decimal(precision, scale)` | numeric | arbitrary precision numbers | `123.45`, `-567.89` |\n|`timesampe` | `date/time` | dae and tiem | `1999-01-08 04:05:06`|\n|`date`| date/time | only a date | `1991-01-08` |\n|`boolean` | `boolean` | true or false | `true`, `false` |\n\n- `NULL` is a special value that represents the absence of any other value.\n- `NULL` values must be compared using `IS NULL` or `IS NOT NULL`.\n- Database dumps can be loaded using `psql -d database_name < file_to_impor.sql`\n- Table columns can have default values, which ares specifed using `SET DEFAULT`.\n- Table columns can be disallowed from storing `NULL` values using `SET NOT NULL`.\n- `CHECK` constraints are rules that must be met by the data stored in a table. \n- A *natural key* is an existing value in a dataset that can be used to uniquely identify each row of data in that dataset.\n- A *surrogate key* is a value that is created solely for the purpose of identifying a row of data in a database table. \n- A *primary key* is a value that is used to uniquely identify the rows in a table.  IT cannot be `NULL` and must be unique within a table. They are created using `PRIMARY KEY`.\n- `serial` columns are typically used to create auto-incrementing columns in PostgreSQL.\n- `AS` is used to rename tables and columns within a SQL statment. \n\n## Relational Data and Joins\n\nThere are some importnat concepts pertaining to relational data that should be understood before we move forward. \n\nRelational databases are called *relational* because they persist data in a set of *relations*.  What is a relation? A table, which is a set of columns and rows of data, is a relation.  PostgreSQL also exposes osme other objects as relations, such as sequences and vies (which we aren't going ot cover in this course).  If you can use somehting in the `FROM` clause in a `SELECT` statment, it's probably a relation.\n\n\nTHe terminology can become confusing, though, when the concetp of *relationships* enter a dicussion.  THw words **relation** and **relationship** are visually similar, but they name two distinct things within a database.  A *relationship* is a connection between entity instances, or rows of data, usually resulting form what those rows of data reporesent.  For example, a row in a *customers* table in a database would probably have a relationship with zero or more rows in an *ordres* table. \n\n*To summarize:*\n\n- a *relation* is usually another way to say \"table\".\n- a *relationship* is an association between the data stored in those relations.\n\nThere are, of course, always subtleties to most technical terms, but our goal is to get you to a place where you can be a productive devleoper.  Mastering the ins and outs of technical jargon takes many, many years.\n\nFor a developer, relational data can be translated into a more funcitonal definition: *working with more than one table at a time*.  There are many reasons to break data up into multiple tables, and considerations about how tables and their keys and constraints interact affects how rows are retrieved, inserted, updated, adn deleted.  In this lesson, we will be focusing on situations involving more than one table in order to illustrate many of these topics. \n\n### Database Diagras: Levels of Schema\n\n*conceptual schema*  High-level design focused on identifying entities and their relationships. *entity relationship model (diagram) (erd)*\n\n*physical schema* low-level database-specific design focused on implementation\n\nThe below table illustrates a relaltionship between tables using *foreign* and *primary* keys. This has an example of one to many relationships. \n\n![Screen Shot 2020-12-24 at 4.11.06 PM.png](quiver-image-url/3BB2694758FC63BBF4C511A02335D4CE.png =769x390)\n\nThis below is an example of a many to many relationship. \n\n![Screen Shot 2020-12-24 at 4.15.55 PM.png](quiver-image-url/B465069FFF25002AEA9CDB72460C1F23.png =576x281)\n\n*Cardinality:* the number of objects on each side of the relationship (1:1, 1:M, M:M)\n\n*modality:* if the realtionship is required (1) or optional (0). \n\nmodality is represented in diagrams like this:\n\n![Screen Shot 2020-12-24 at 4.49.32 PM.png](quiver-image-url/A2D0EEF1AB228D4FA4243D2256E6B1EC.png =571x256)\n\nbelow is an example of a conceptual schema using modality:\n\n![Screen Shot 2020-12-24 at 4.52.48 PM.png](quiver-image-url/B8F7F1B2A8629B40947A6E6204FF806F.png =381x255)\n\nin the above diagram entity relationship model.  The modality says that a book has to have and author and an author has to have at least one book. It then says the a category can have 0 or more books and a book can be in 0 or more categetories (its optional). \n\n\n![Screen Shot 2020-12-24 at 4.56.51 PM.png](quiver-image-url/D5FFE5B3389871FBD77A54770C759E9D.png =440x263)\n\nlooking at the diagram above a Ticket must have 1 (and only one seat) and a seat can have 0 or many tickets. \n\n\n## Using Foreign Keys\n\nIn database parlance, a *foreign key* can refer to two different, but related things:\n\n- A column that represents a relationship between two rows by pointing to a specific row in another table using its **primary key**.  A complete name for these columns is **foreign key* column. \n- A constraint that enforeces certain rules about what values are permitted in these foreign key relationships.  A complete name for this type of cconstraing is **foreign key constraint**.\n\nLet's take a look at a simple relationship between the two entities and see how each of these applies. We'll work with a database that has two entities, Product and Order:\n\n![Screen Shot 2020-12-29 at 2.21.57 PM.png](quiver-image-url/368CCC2B5696872676A368E532FC94E7.png =422x116)\n\nyou can see above that products have many ordres. One that ERD is translated into a physical schema, we might have something like this\n\n![Screen Shot 2020-12-29 at 2.22.48 PM.png](quiver-image-url/E76C22EF552B5B903759DE4092B02AE4.png =485x129)\n\nIn the above schema, the **product_id** column is a foreign key, pointing to values in the primary key column of rows in the *products* table.\n\n#### Creating Foreign Key Columns\n\nTO create a foreign key **column**, just create a column of the same type as the primary key column it will point to.  Since the `products` table shown above uses and `integer` type for its primary key column, `orders.product_id` is also an `integer` column\n\n#### Creating Foreign Key Constraints\n\nTO create a oreign key **constraint**, there are two syntaxes that can be used.  The first is to add a `REFERENCES` clause to the description of a column in a `CREATE TABLE` statement:\n\n```\nCREATE TABLE orders (\n  id serial PRIMARY KEY,\n  product_id integer REFERENCES products (id),\n  quantity integer NOT NULL\n  );\n```\n\nTHe second way is to add the foreign key constraint separately, just as you would any other constrain (not the use of `FOREIGN KEY` instead of `CHECK`):\n\n```\nALTER TABLE orders ADD CONSTRAINT orders_product_id_fkey FOREIGN KEY (product_id) REFERENCES products (id);\n```\n\n#### Referential Integrity \n\nONe of the main benefits of using the foreign key constraints provided by a relational database is to preserve the **referential integrity** of the data in the database.  The database does this by ensuring that every value in a foreign key column exists in the prmary key column of the table being refereced.  ATTMPETS to insert rows that violate the table's contraints will be rejected. \n\n\n## One-to-many Relationships\n\nConsider a table containing information about calls:\n\n![Screen Shot 2020-12-29 at 3.56.32 PM.png](quiver-image-url/A7ADB5739DD7E8116BE5613AD67F6929.png =582x200)\n\nFor each call, this table stores a primary key, when the call was made, how long the call was, the first anc last names of the contact, and the phone number the call was made to.\n\nSo far, so goo, Now consider whtat happends when we add more phone calls with people who have already been called:\n\n![Screen Shot 2020-12-29 at 3.58.40 PM.png](quiver-image-url/181AD07407FEBD474D7B2D1ECE053251.png =579x245)\n\nat first everything looks OK, and in some ways, it is.  We're still storing all of the data. But there are some issues with the schema we're using that adding these new rows helps illustrate.\n\nThe first thing that you might notice is that there is duplicate data in the table:  The first name, last name, and number for th enew rows already appeared in earlier rows.  This is the result of the schema design and can lead to a serious problem:\n\n- If a contact's name or phone number needs to be changed, we'd need to update eveyr row that contianed information about that contact.  This creates a situation where it would be easy to make the database inconsistent, which means that it contains more than one answer for a given question.  If this occurred, it would be known as *update anomaly*.\n\nThere are other issues with this table's schema that limi how useful it is:\n\n- we can't store the information for a contact wihtout having placed a call to them.  This is known as an *insertion anomaly*.\n- Likewise, we lose all the information about a contact if we delete the history of calls to them.  This is knwon as a *deletion anomaly*.\n\nYou migh tbe wondering if having this duplicaiton is a waste of space.  Especially as the amount of data increases,  these kind of duplicaitons can really add up. It's best to not worry about how much space it takes to store data when thinking about normalization,, and instead think about the three anomalies.  Sometimes it is actually desireable to have data duplicated (or *denormalized*) as it can make some retrieval operations much more efficient.\n\n*Normalization* is the process of designing schema that minimize or eliminate the possible occurence of these anomalies. The basic procedure of normalization invovles extracting data into additional tables and using foreign keys to tie it back to its associated data. \n\nrecall that a *foreign key column* is a column that stores references to a primary key column elsewhere in a database.  Foreign keys usually point to other tables, but there are ceases where they will point to rows int the same table.\n\nso far, we've been working with a database that looks like this: \n\n![Screen Shot 2020-12-29 at 4.11.13 PM.png](quiver-image-url/DBBA5BD26B50926765448B6CAD95BEF3.png =329x167)\n\nLet's see what happens when we apply the normalization proces to the `calls` table by extracting all datab about contacts into a new *contacts* table:\n\n![Screen Shot 2020-12-29 at 4.12.13 PM.png](quiver-image-url/9D583894DC82114A637D686AE119DF22.png =650x161)\n\nWhen applied to the data we've been working with, we end up with something like this:\n\n![Screen Shot 2020-12-29 at 4.13.17 PM.png](quiver-image-url/F577C320F9691BC98AC6B21263D93EB3.png =728x254)\n\nThe first thing you'll probably notice is that the duplicaiton we detected earlier is no longer present.  The rows of data in each table are connected by the values tored by `calls.contact_id`, each of which is the value of an `id` column in an associated `contacts` row.  The following chart has colored the rows in each table to help illustrate how they are related:\n\n![Screen Shot 2020-12-29 at 4.15.49 PM.png](quiver-image-url/101230E866B888D16E702C4B8D68898F.png =774x246)\n\nWhile separating the data into two tables helped address the anomalies listed earlier, it has made it so we can no longer acess all of the data by using a simple `SELEC * FROM calls` statment. we still would like to be able to see it all together in the following format:\n\n![Screen Shot 2020-12-29 at 4.17.09 PM.png](quiver-image-url/79A4123871943F3BB798E01C848621EF.png =569x232)\n\nFortunately, there is a way to do this, and it doesn't inovle too much more work.  We just need to specify in our SQL statement that we want data from both tables to be returned.  A first attempt might be just to list both tables in the `FROM` clause:\n\n![Screen Shot 2020-12-29 at 4.18.52 PM.png](quiver-image-url/D5B22534166ED75C0B2674368391FCEF.png =822x466)\n\nThis.. didn't work!  The rows of data we want are in the reuslts if w look carefully, but they are surrounded by rows of data that don't make sense as they contain call data and contact data for contacts other than those that we actually called. The rows wehre the `contact_id` and second `id` columns match are the ones we actually want:\n\n![Screen Shot 2020-12-29 at 4.20.20 PM.png](quiver-image-url/180E363119DEA9AA35A625916003EB49.png =798x475)\n\nWhen we list multiple tables within a `SELECT` statement's `FROM` caluse, the database will return every possible combination of rows from the listed tables.  Most of the time, this is not what we want, because it connects rows in the tables that aren't actually related.  And while this is fairly obvious to use, the database doesn't have any way to know how we expect it to connect the rows in the two tables we list.  The above output *is* technically a valid result, only it's not the result we want.\n\nWhat we need to do is tell the database *how* to connect the rows in the two tables so it can return just data that makes sense.  We do this by telling it to use the foreign key in the *calls* table, `contact_id`, to match rows in *calls* to rows in *contacts* based on their `id`.  \n\nWe can do this by using a `JOIN` clause and specifying how to connect the two tables:\n\n```\nSELECT * FROM calls INNER JOIN contacts ON calls.contact_id = contacts.id;\n```\n\nLet's take this statement apart:\n\n\n\n### Many-to-Many relationships \n\n\nSo far we've looked at one-to-manhy relationships and how to represent them in a relational database.  Many of the relationships in a typical application will be one-to-many, but there are times where a different tyep of relationships allows a more accurate modeling of the information. \n\n*Many-to-many* relationships are those where there can be multiple instnaces on both sides of the relationship. YOu can think of them as one-to-many relationships that go from the first table to the second *and* from the second table to the first.\n\nLet's look at an example. Let's say we have an application that needs to store data about books and the categories they belong to.  We might have an entity relationship diagram like this one:\n\n![Screen Shot 2020-12-30 at 3.53.50 PM.png](quiver-image-url/2D050E4376344968CDA69E2165AACDDB.png =420x119)\n\nAs shown in the diagram, books can have many categries *and* categories cna have many books. FOr example, GU, with Occasional Music might belong to the categories `science fiction`, `detective`, and `fuction`, while the category `science fiction` is going to also include many other books including Dune.\n\nTranslating the above diagram into a physical Schema gives us something like this:\n\n![Screen Shot 2020-12-30 at 3.56.11 PM.png](quiver-image-url/03019E7452A99B8BB714CE210B4FA5C8.png =845x132)\n\nNotice the use of a new table, `books_categories`, which is responsible for storing information about the relationships between specific books and categories.  Such a table that is used to persist the state of many-to-many relationships is called a **join table**. \n\n*Should Join Tables include a primary key column*\n\n*it depends*.  You might have noticed that the `books_categories` table doesn't have an `id` column.  This is because it is possible to identify any row in this table using a combination of the values for both its `book_id` and `category_id` \n\n## Converting a 1:M RElationship to a M:M Relationship\n\nAs applications grow and their requirements change, it is fairly common for the realtionships to change from one type to another.  One example of this is needing to change a one-to-many relationship into amany-to-many relationship.\n\nLet's go back to the movies database we were looking at earlier.  We had extracted all of the information about directors out of the `films` table and put it in a new `directors` table.  After thi change, we we working with a system that could be described by this ERD:\n\n![Screen Shot 2020-12-31 at 10.51.15 AM.png](quiver-image-url/DF8F02FD7EF992F912245FD3E87D41B7.png =421x127)\n\nThis design works well enough for many movies.  However, as we continue to add more and more films to the database, we're going to start running into some problems. It turns out that not all films have a single director!\n\nConsider the film **No Country for Oled Men* which was directed by Joel Coen *and* Ethan Coen.  How would we handle this film with our current design?  We could jus use \"The Coen Borthers\" of \"Joel and Ethan Coen\"  as the director.  But then we still have to deal with films that only one of them directed, such as *Fargo*,  which was directed by Joel Coen.\n\nUltimately, the right solution is going to be to change our design to allow multiple directors for a film.   We need to move to something like this:\n\n![Screen Shot 2020-12-31 at 10.55.35 AM.png](quiver-image-url/77C4669738D8FEB98670CCEF03874C3C.png =446x125)\n\nBased on what we saw in the last assignment, we know this is going to mean adding a **join table** to the database to store the relationships between directors and filsm.\n\n\n###summary \n\n- **relational databases** are called relational because they persist data in a set of *relations* or they are more commonly called, tables.\n- A **relationship** is a connection between entity instances, or rows of data, usuallly resulting from what these rows of data represent. \n- The three levels of schema are *conceptual*, *logical*, and *physical*.\n- The three type levels of shcema are **conceptual**, **logical** and **physical**\n- The three types of relationships are **one-to-one**, **one-to-many**, **many-to-many**\n- a **conceptual schema** is a high level design focused on identifying entities and their relationships.\n- a **physical schema is a low-level database-specific design focused on implementation.\n- a **cardinality** is the number of objects on each side of the relationship.\n- The **modality** of a realtionship indicates if that relationship is required or not.\n- *Referential integrity** is a data that requires all references to be valid.  That is if a value in a column references a value in another column (usually in another table), then that value must exist in the referenced column. \n\n# Indexes\n\nAnother potential way of optimizing a database-backed applicaiton is to add indexes to the database tables.  We very briefly ention indexes in our Introduciton to SQL book, but wihtout going into much detail or discussing how to implment them;  in this assignment we're going to take a bit of a closer look.  Indexes is a deep and complex topic, and not one that it's necessary to fully explore at this point, but by the end of this assignmnet you should have a clearer understanding of what indexes are, when to use them, and how to implment them. \n\n## What are indexes?\n\nIn the context of a database, an index is a mechanism that SQL engines use to speed up queries.  They do this by storing indexed data ina table-like structure, which can be quickly searched using particular search algorithms.  The results of the search provide a link back to the records(s) to which the indexed data belongs.  Using an index means that the database engine can locate column values more efficiently since it doesn't have ot search through every recrod in a table in sequence.\n\nOne way to visualize how database indexes work is to think of the index in a book.  Reference books often index key terms and proper names, listing all the pages where those terms occur. if you want to fina and indexed term in tbe book, you just serach the index and you'll know hich pages to go to.\n\nIn the same way, having a index on the column of a database table enables fast lookpu.  Let's look at an example. Say we had a table of books and their authors. \n\n![Screen Shot 2021-01-03 at 7.24.55 PM.png](quiver-image-url/8831255F3409702E931D2BD0841E1A10.png =740x267)\n\nIf I wanted to query all the book titles for books by a particular authoer, PostgreSQL would need to go through the table row by row to find each rwo where the author name matches the search condition\n\n![Screen Shot 2021-01-04 at 12.33.23 PM.png](quiver-image-url/1D746AA46A6631C4C7C06BDEE941EABE.png =749x279)\n\n\ni we indexed the `author` column, instead of seraching each row in the table, PostgreSQL would just need to serach the index fo the name that matched the search condition in order to identify the relevant rows\n\n![Screen Shot 2021-01-04 at 12.34.42 PM.png](quiver-image-url/6415BC6398DA1A325CE92F36636D968B.png =838x220)\n\nIn a real database, our `author` column would probably be a Foreign Key id instead, but the principle remains the same. \n\n## When to use an index?\n\nthe question you might be asking is, if indexes are so useful for speeding up queries then why not just index every column in a table?  People often do this, and end up with slower tables.  There are numerious reasons for this slowness; one reason being that when you build an index of a field, reads become faster, but every time a row is updated or inserted, the index must be updated as well.  Now you're updating not only the table but also the index, so that's a performance cost.  As with many database optimization decisions, there are a lot of choices involved in how to decide whether or not a column should be designated an index.\n\nMaking such choices is often about trade-offs. there are some useful rules of thumb that can help when assessing what those trade-offs are:\n\n- Indexes are best used in cases where sequential reading is inadequate.  For ecample: columns that aid in mapping relationships (such as Foreign Key columns), or columns that are frequenctly used as part of an `ORDER BY` clause, are good candidates for indexing. \n- They are best used in tables and/or columns where the data will be read much more frequently than it is created or updated. \n\n### Types of Index\n\nAnother decision when using indexes is the type of index to use.  Different types of index use different data structures and different search algorithms.  Some of the index types available within PostgreSQL are B-tree, Hash, GiST, and GIN.  For the purposes of htis course, you don't need to remember these types, understand how they work, or know the differences between them.  If you are interested in reading further about this topic, the PostgreSQL documentation is a good place to start; this is by no means required reading however.\n\n### Creating Indexes\n\nAt this point in the course you will already have created indexes on columns, though not explicitly.  When you define a `PRIMARY KEY` constrating, or a `UNIQUE` constraint, or a `UNIQUE` constraint, on a column you automatically create an index on that column.  in fact, the index is the mechanims by which these constraints enforce uniqueness. \n\nExamine the table creation statments below, along with the schema for the `books` table:\n\n```\nmy_books=# CREATE TABLE authoers (\n  id serial PRIMARY KEY,\n  name varchar(100) NOT NULL\n);\n\nmy_books=# CREATE TABLE books (\n  id serial PRIMARY KEY,\n  title varchar(100) NOT NULL,\n  isbn char(13) UNIQUE NOT NULL,\n  author_id int REFERENCES authors(id)\n):\nmy_books(#  CREATE TABLE\nmy_books=# \\d books\n\n                      Table \"public.books\"\n     Column     |          Type          |                     Modifiers\n----------------+------------------------+----------------------------------------------------\n id             | integer                | not null default nextval('books_id_seq'::regclass)\n title          | character varying(100) | not null\n isbn           | character(13)          | not null\n author_id      | integer                |\nIndexes:\n  \"books_pkey\" PRIMARY KEY, btree (id)\n  \"books_isbn_key\" UNIQUE CONSTRAINT, btree (isbn)\nForeign-key constraints:\n  \"books_author_id_fkey\" FOREIGN KEY (author_id) REFERENCES authors(id)\n\n```\n\nIn the description of the table schema, we can see two entries listed under `Indexes:`, `books_pkey`, and `books_isbn_key`.  The `btree` part of each entry indentifies the type of index used (PostgreSQL uses B-tree by default for all indexes, and it is the only type available for unique indexes), followed by the name of the column that is indexed.\n\nUnlike `PRIMARY KEY` and `UNIQUE` constraints, `FOREIGN KEY` constraints do not automatically create an index on a column.  Foreign Key columns are good candidates for indexing, however you would need to explicityly create the index on the column.  Let's look at how to do that next.\n\nThe general form for adding an index to a table is:\n\n```\nCREATE INDEX index_name ON table_name (field_name);\n```\n\nIf `index_name` is omitted, PostgreSQL automatically generates a unique name for the index.  If you want to specify your own name fo rthe index, it must be a name that hasn't already been used.\n\nTo add an index to the `author_id` column on the `books` table, we could execute the following statment:\n\n```\nmy_books=# CREATE INDEX ON books (author_id);\nCREATE INDEX\n```\nIf we now look at schema for the table, we can see that there is another entry, `books_author_id_idx`, listed under `Indexes:`;\n\n```\n\nmy_books=# \\d books\n                         Table \"public.books\"\n     Column     |          Type          |                     Modifiers\n----------------+------------------------+----------------------------------------------------\n id             | integer                | not null default nextval('books_id_seq'::regclass)\n title          | character varying(100) | not null\n isbn           | character(13)          | not null\n author_id      | integer                |\nIndexes:\n  \"books_pkey\" PRIMARY KEY, btree (id)\n  \"books_isbn_key\" UNIQUE CONSTRAINT, btree (isbn)\n  \"books_author_id_idx\" btree (author_id)\nForeign-key constraints:\n  \"books_author_id_fkey\" FOREIGN KEY (author_id) REFERENCES authors(id)\n\n```\n\n###Unique and Non-unique\n\nWhen an index is created via `PRIMARY KEY` or `UNIQUE` constraints, the index created is a **unique** index.  When an index is unique, multiple table rows with the equal values for that index are not allowed.  The `books_pkey` and `books_isbn_key` indexes indexes in the `books` table are unique indexes and it is not possible to insert duplicate values in the columns that they index.  The `books_author_id_idx` index that we added doesn't enforce uniqueness, meaning that the same value can occur multiple times in the indexed column.  This is sometiems referred to as a non-unique index. \n\n### Multicolumn Indexes\n\nAs well as indexing a single column, indexes can also be create on one more than one column.  The form is almost the same as a signle-column index, except instead of specifying a single column name, you specify more than one:\n\n```\nCREATE INDEX index_name ON table_name (field_name_1, field_name_2);\n```\n\nonly certain index types support multi-column indexes, and there is a limit to the number of columns that can be combined in an index.\n\n### Partial Indexes\n\nAnother form of index is a partial index.  Partial indexes are built from a subset of the data in a table.  The subset of data is defined by a conditional expression, and the index contains entries only for th rows from the table where the value in the indexed column satifies the condition. Going back to our earlier `author_name` example, we could perhaps index only rows wehre the value `author_name` column starts with an `A`.\n\nPartial indexes can be useful in certain situation,s but most of the time you will be using single-column or perhaps multicolumn indexes.\n\n### Deleting Indexes\n\nThe `DROP INDEX` command can be used to delete the index that was created.  In order to execute the commn you need to refer to the index by its name. \n\nRather than displaying the entire schema for a table, another way of listing indexes is to use the `\\di` psql console command.  This is similar to the `\\d` command, execept rather than listing the tables, views, and sequences of a databse it list the indexes. \n\n\n```\nmy_books # \\di \n              List of relations\n Schema |        Name         | Type  | Owner |  Table\n--------+---------------------+-------+-------+---------\n public | authors_pkey        | index | User  | authors\n public | books_author_id_idx | index | User  | books\n public | books_isbn_key      | index | User  | books\n public | books_pkey          | index | User  | books\n(4 rows)\n\n```\n\nabove we can see that there a three indexes on the `books` table, and one on the `authors` table.\n\nLet's delete the `books_author_id_idx` we created earlier:\n\n```\n\nmy_books=# DROP INDEX books_author_id_idx;\nDROP INDEX\n\n```\n\nIf we now list the indexes in our database, we will see that the `books_authoer_id_idx` index is no longer there:\n\n```\n\nmy_books=# \\di\n                 List of relations\n Schema |      Name      | Type  | Owner |  Table\n--------+----------------+-------+-------+---------\n public | authors_pkey   | index | karl  | authors\n public | books_isbn_key | index | karl  | books\n public | books_pkey     | index | karl  | books\n(3 rows)\n```\n\n## Comparing SQL Statements\n\nThroughout this course you've seen that there are often many ways to structure a SQL query in order to achieve the same results.  Using a subquery rather than a join might be on might be on obvious example, but differences can also be subtler than that, such as the kind of join used of choice of `WHERE` condition.\n\nYou might be wondering what difference it makes how we structure a query if the result is the same.  An important difference is in the amount of time it takes for the query to run.  If your application is only dealing wtih small data-sets or executing low numbers of database queries, those time differences might not be worth worrying about. Once you start to scale your applicaiton however, those little differences may start to add up and present an opportunity for optimization.\n\nYou may recall that when discussing `THE SQL Language` earlier in the course we talked about SQL being a predomincatly *declarative language*,  in that it describes **what needs** to be done but no the detail of how to do it.  The details of how a query is actually run are abstracted away by the databse engine, however it is possible to influence this process by the way you struture your SQL statments.  How, then, do we decide on the best way to structure our queries in order to optimize them?  One approach is to compare different queries that produce the same output by assessing how efficient they are to run.  \n\n### Assessing a Query with EXPLAIN\n\nPostgreSQL provides a useful command called `EXPLAIN` which gives a step by setp analysis of how the query will be run internally by PostgreSQL.\n\nIn order to execute each query that it receives, PostgreSQL devises an appropriate *query plan*.  The creation of this query plan is one step in the path of executing a query as outlined in the PostgreSQL Documentaiton.  What `EXPLAIN` does is allow you to access and read the query plan.\n\nTo use `EXPLAIN` you prepend the query with the `EXPLAIN` keyword.  This does not actually exevute the query, but instead returns the query plan for that query.\n\n```\nmy_books=# EXPLAIN SELECT * FROM books;\nQUERY PLAN\n----------------------------------------------------------\n Seq Scan on books  (cost=0.00..12.60 rows=260 width=282)\n(1 row)\n\n```\n\nThe structure of the query plan is a node-tree. THe more 'elements' that there are to your query, the more nodes there will be in the tree.  The example above explains a very simple query, so there is only one node in the plan tree. Each node consists of the node type (in this case  sequential scna on the `books` table) along with estimated cost for th enode (start-up cost, flllowed by total cost),  the estimated number of rows to be output by the node, and the estimate average width of the rows in bytes. \n\nTHe cost values are calculated using arbitrary units determined by the planner's cost parameters, and represent the estimated amount of effort or resources required to execute the query as planned.  Understanding cost parameters is beyond the scopre of this course, but is explained in detail in the PostgreSQL documentaiton\n\nThe output for a more complext query would have more nodes:\n\n```\nmy_books=# EXPLAIN SELECT books.title FROM books JOIN authors ON books.author_id = authors.id WHERE authors.name = 'William Gibson';\n\nQUERY PLAN\n--------------------------------------------------------------------\nHash Join  (cost=14.03..27.62 rows=2 width=218)\n  Hash Cond: (books.author_id = authors.id)\n  ->  Seq Scan on books  (cost=0.00..12.60 rows=260 width=222)\n  ->  Hash  (cost=14.00..14.00 rows=2 width=4)\n        ->  Seq Scan on authors  (cost=0.00..14.00 rows=2 width=4)\n              Filter: ((name)::text = 'William Gibson'::text)\n(6 rows)\n```\n\nHowever many nodes the plan has, one of the key pieces of information to look out for in order to compare queries is the estimated 'total cost' value of the top-most node.  For our first query this value is `12.60`.  Our second, more complex, query understanably has a higher estimated cost of `27.62`.  \n\nFor a more interesting comparision, we can replace our second example with and equivalent subquery:\n\n```\nmy_books=# EXPLAIN SELECT title FROM books\nmy_books-# WHERE author_id =\nmy_books-# (SELECT id FROM authors\nmy_books(# WHERE name = 'William Gibson');\n                                     QUERY PLAN\n-------------------------------------------------------------------------------------\n Index Scan using books_author_id_idx on books  (cost=14.15..22.16 rows=1 width=218)\n   Index Cond: (author_id = $0)\n   InitPlan 1 (returns $0)\n     ->  Seq Scan on authors  (cost=0.00..14.00 rows=2 width=4)\n           Filter: ((name)::text = 'William Gibson'::text)\n(5 rows)\n```\n\nLooking at the two outputs, the estimated cost for the subquery, `22.16` is lower thn that for the join `27.62`.  This is not necessarily alwasy the case, and often joins are more efficient than subqueries.\n\n###EXPLAIN ANALYZE\n\nAn important thing to remember is that when you use `EXPLAIN`, the query is not actually run.  the values that `EXPLAIN` outputs are estimates, based on the planner's knowlege of the schema and assumptions based on PostgreSQL systme statistics.  In order to assess a query using actual data, you can add the `ANALYZE` option to an `EXPLAIN` command.\n\n```\nmy_books=# EXPLAIN ANALYZE SELECT books.title FROM books\nmy_books-# JOIN authors ON books.author_id = authors.id\nmy_books-# WHERE authors.name = 'William Gibson';\n                                                  QUERY PLAN\n--------------------------------------------------------------------------------------------------------------\n Hash Join  (cost=14.03..27.62 rows=2 width=218) (actual time=0.029..0.034 rows=3 loops=1)\n   Hash Cond: (books.author_id = authors.id)\n   ->  Seq Scan on books  (cost=0.00..12.60 rows=260 width=222) (actual time=0.009..0.012 rows=7 loops=1)\n   ->  Hash  (cost=14.00..14.00 rows=2 width=4) (actual time=0.010..0.010 rows=1 loops=1)\n         Buckets: 1024  Batches: 1  Memory Usage: 9kB\n         ->  Seq Scan on authors  (cost=0.00..14.00 rows=2 width=4) (actual time=0.006..0.007 rows=1 loops=1)\n               Filter: ((name)::text = 'William Gibson'::text)\n               Rows Removed by Filter: 2\n Planning time: 0.201 ms\n Execution time: 0.074 ms\n(10 rows)\n\n\n```\n\nUsing the `ANALYZE` option acutally runs the query and, in addition to the output normally returned by `EXPLAIN`, includes the actual time (in milliseconds) required to run the query and its constituent parts, as well as the actual rows returned by each plan node node rather than just a number of rows based on defaults statiscs. \n\n### Subqueries\n\nALthough it's not alwasy the case, we've already seen that there are situations where a subquery can be more efficient than using a join.  When comparing different queries as part of an optimization proces, it can stometimes be useful to test out some subqueries.  In order to do so you need to have a good understanding of how they work, so in thie assignment were' going to eexplore subqueries a bit furhter.  BEfore proceding you might wnat to review this secion on subqueres.\n\nIf you are more familair wiht using joins, then subqueries may seem like an unusul way to structure a SQL statement.  The key thing to understand conceptually is that you are using the nested query to generate a set of one ore more values, you then use those values as part of an outer query (usually a part of a condition).\n\nLet's break dwon the example form the previous assignment, where we return the titltes of books by a certain author.  The entire query looks like this:\n\n\n```\nSELECT title FROM books WHERE author_id = (SELECT id FROM authors WHERE name = 'William Gibson');\n```\n\nThe nested query, when executed, returns the `id` value form the `authors` table for `'william Gibson'`, which is the integer `1`:\n\n```\n\nmy_books=# SELECT id FROM authors WHERE name = 'William Gibson';\n id\n----\n  1\n(1 row)\n```\n\nThe 'outer' query uses that value in the `WHERE` condition, and so effectively becomes this:\n\n```\nSELECT title FROM books WHERE author_id = 1;\n```\n\n### Subquery Expressions\n\n### Subquery Expressions\n\nIn the above example, we were able to use `=` in the `WHERE` condition in this way because the nested query returned a singel value.  Much of the time when using subqueries, the nested query will return more than one value; this is where subquery expressions become useful.\n\nSubquery expressions are a sepcial set of operators for use specifically with subqueries, most commonly within a conditional subquery.  The various subquery expressions available in PostgreSQL are briefly descibed bllow. \n\nBefore w run through the various suqbqueries, let's look  at what data existins in our tables: \n\n\n```\nmy_books=# SELECT * FROM authors;\n id |      name\n----+----------------\n  1 | William Gibson\n  2 | Iain M. Banks\n  3 | Philip K. Dick\n(3 rows)\n\nmy_books=# SELECT * FROM books;\n id |        title         |     isbn      | author_id\n----+----------------------+---------------+-----------\n  1 | Neuromancer          | 9780441569595 |         1\n  2 | Consider Phlebas     | 9780316005388 |         2\n  3 | Idoru                | 9780425158647 |         1\n  4 | The State of the Art | 0929480066    |         2\n  5 | The Simulacra        | 9780547572505 |         3\n  6 | Pattern Recognition  | 9780425198681 |         1\n  7 | A Scanner Darkly     | 9780547572178 |         3\n(7 rows)\n\n```\n\n### Exists\n\n`Exists` effecitively checks whether *any* rows at all are returned by the nested query.  If at least one row is returned then the result of `EXISTS` is `true`, otherwise it is `false`. \n\n```\nmy_books=# SELECT 1 WHERE EXISTS (SELECT id FROM books WHERE isbn = '9780316005388');\n ?column?\n----------\n        1\n(1 row)\n\n```\n\nThis would return `1` if there is a row in the `books` table with an `isbn` of `9780316005388`, and return no rows otherwise.  `EXISTS` is somehwat unusual, but can be useful in some situations such as in **correlated subqueries** (which we won't go into here). \n\n###IN\n\n`IN` compares an evaluated epxression to every row in the subquery result.  If a row equal to the evaulatd expression is found, then the result of `IN` is 'true', otherwise it is 'false'.\n\nExample:\n\n```\nmy_books=# SELECT name FROM authors WHERE id IN (SELECT author_id FROM books WHERE title LIKE 'The%');\n\nname\n----------------\n Iain M. Banks\n Philip K. Dick\n(2 rows)\n```\n\nHere, the nested query returns a list of `author_id` values `(2, 3)` from the `books` table where the `title` of the book for that row starts with `The`.  The outer query that returns the `name` value from any row of the `authors` table, where the `id` for that row is in the results from the nested query.\n\n### NOT IN\n\n`NOT IN` is similar to `IN` except that the result of `NOT IN` is `true` if an equal row is *not* found, and 'false' otherwise. \n\nExample:\n\n```\n\nmy_books=# SELECT name FROM authors WHERE id NOT IN\nmy_books-#   (SELECT author_id FROM books\nmy_books(#     WHERE title LIKE 'The%');\n      name\n----------------\n William Gibson\n(1 row)\n```\n\nHere, the nested query again returns a list of `author_id` values `(2, 3)` from the `books` table where the `title` of the book for the row starts with `The`.  The outer query then returns the `name` value from any row of the `authors` table, where the `id` is not in results from the nested query.\n\n### ANY/SOME\n\n`ANY` and `SOME` are synonyms, and can be used interchangeably.  these expressions are used along with an operator (e.g. `=`, `<`, `>`, etc).  The result of `ANY`/`SOME` is 'true' if any true result is obtained when the expression to the left of the operator is evaulated using that operator against the results of the nested query. \n\n\nEXAMPLE:\n\n```\n#my_books=#  SELECT name FROM authors WHERE length(name) > ANY\n(SELECT length(title) FROM books WHERE title LIKE 'The%');\n     name\n----------------\n William Gibson\n Philip K. Dick\n(2 rows)\n\n```\n\nHere, the nested query returns the string length of any book `title` starting with `The`, `(20,13)`.  The outer query then returns the `name` of any author where the length of `name` is greater than *any* of the results form the nested query.  Two of the author names are 14 characters in lenght and so satisfy the condition since they are greater in length than **at least one** of the tilte lengths(`13`)from the results of the nested query. \n\nNote when the `=` operator is used with `ANY/SOME`, this is equivalent to `IN`.\n\n###ALL\n\nAs with `ANY`/`SOME`, `ALL` is used along with an operator.  the reult of `ALL` is true only if **all** of the results are true when the expression to the left of the operator is evaluated using the operator agains the results of the nested query.\n\nExample:\n\n```\nmy_books=#  SELECT name FROM authors WHERE length(name) > ALL (SELECT length(title) FROM books WHERE title LIKE 'THE%');\nname\n------\n(0 rows)\n```\n\nHere, the nested query again returns the string lenght of any book `title` starting with 'The', `(20, 13)`.  The outer query then returns the `name` of any author where the length of `name` is greater than **all** of the results from the nested query.  On this occasion no resutls are rturened by the outer query, since the lnegths of the author names would need to be greater than **all** of the title lengths, `(20,13)` in orer to satisfy the condition. \n\nNote: when the `<>`/`!=` operator is used with `ALL`, this is equvialent to `NOT IN`.\n\nMore information can be found on these subquery expression in the PostgreSQL documentation \n\nIn the next assignment we'll practice using some of these subquery expressions, as well as exploring the other uses for subqueries. \n\n### When to use Subqueries\n\nWe've seen that when comparing subquereis and joins that produce the same results, one can somtimes be faster than the other.  When first formulating your quereis however, you probably arent' testing them for speed; optimization usually comes as a later step in a project.\n\nWhen you're not yet at the optimization stage and performance isn't a factor, the decision over wheter to us a subquery over a join will often come down to personal preference.  There are however valid arguments to say that subquereies are more readbale to make more logical ssense in some situations. For example, if you want to return data from one table conditional on data from another table, but don't need to return any data from the second table, then a subquery may make more logical sense and be more readable.  If you need to return data from both tables then you would need to use a join. \n\n"
    },
    {
      "type": "text",
      "data": ""
    },
    {
      "type": "text",
      "data": "<br>"
    },
    {
      "type": "text",
      "data": "<div><br></div><div><br></div><div><br></div>"
    }
  ]
}